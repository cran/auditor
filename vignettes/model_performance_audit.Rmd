---
title: "Model Performance Audit"
author: "Alicja Gosiewska"
date: "`r Sys.Date()`"
output: html_document
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Model Performance Audit}
  %\usepackage[UTF-8]{inputenc}
---


```{r setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```



# Regression use case - dragons data

To illustrate applications of *auditor* to regression problems we will use an artificial dataset dragons available in the [*DALEX*](https://github.com/pbiecek/DALEX) package. Our goal is to predict the length of life of dragons.

```{r}
dragons <- DALEX::dragons
head(dragons)
```

# Models


## Linear model
```{r}
lm_model <- lm(life_length ~ ., data = dragons)
```



## Random forest
```{r}
library("randomForest")
set.seed(59)
rf_model <- randomForest(life_length ~ ., data = dragons)
```


# Preparation for error analysis
The beginning of each analysis is creation of an `explainer` object with the DALEX package. Itâ€™s an object that can be used to audit a model.

```{r}
lm_exp <- DALEX::explain(lm_model, label = "lm", data = dragons, y = dragons$life_length)
rf_exp <- DALEX::explain(rf_model, label = "rf", data = dragons, y = dragons$life_length)
```


# Model Performance Audit

## Model Ranking radar plot

Model performance measures may be plotted together to easily compare model performances.

Function `model_performance()` compute chosen model performance measures. A result further from the center means a better model performance.

```{r}
library(auditor)
lm_mp <- model_performance(lm_exp)
rf_mp <- model_performance(rf_exp)

lm_mp
```

Results of `model_performance()` function for multiple models may be plotted together on one plot.
Parameter `table` indicates whether the table with scores should be generated.

On the plot scores are inversed and scaled to [0,1].

```{r}
plot(lm_mp, rf_mp)
```

There is a possibiliy to define functions with custom model performance measure.

```{r}
new_score <- function(object) sum(sqrt(abs(object$residuals)))

lm_mp <- model_performance(lm_exp,  
                          score = c("mae", "mse", "rec", "rroc"), 
                          new_score = new_score)

rf_mp <- model_performance(rf_exp,  
                          score = c("mae", "mse", "rec", "rroc"), 
                          new_score = new_score)

plot(lm_mp, rf_mp)
```



# Other methods

Other methods and plots are described in vignettes: 

* [Model Residuals audit](https://modeloriented.github.io/auditor/articles/model_residuals_audit.html)

* [Model Evaluation audit](https://modeloriented.github.io/auditor/articles/model_evaluation_audit.html)

* [Model Fit audit](https://modeloriented.github.io/auditor/articles/model_fit_audit.html)

* [Observation Influence audit](https://modeloriented.github.io/auditor/articles/observation_influence_audit.html)


